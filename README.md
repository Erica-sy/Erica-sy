## Papers
### Multimodal fusion
#### 2024
- Audio-Visual Person Verification based on Recursive Fusion of Joint Cross-Attention [arXiv 2024] [paper](http://arxiv.org/abs/2403.04654) [code](https://github.com/praveena2j/RJCAforSpeakerVerification)
- Dynamic Cross Attention for Audio-Visual Person Verification [arXiv 2024] [paper](http://arxiv.org/abs/2403.04661) [code]( https://github.com/praveena2j/DCAforPersonVerification)
- Multimodal Speaker Recognition using voice and lip movement with decision and feature level fusion [IEEE] [paper](https://www.researchsquare.com/article/rs-2960709/v1)
- Unsupervised Speaker Diarization in Distributed IoT Networks Using Federated Learning [arXiv 2024] [paper](https://arxiv.org/pdf/2404.10842)
- Audio-Visual Target Speaker Extraction with Reverse Selective Auditory Attention [arXiv 2024] [paper](https://arxiv.org/abs/2404.18501) [dataset](https://github.com/smeetrs/deep_avsr)
- 3D-Speaker-Toolkit: An Open Source Toolkit for Multi-Modal Speaker Verification and Diarization [arXiv 2024] [paper](https://arxiv.org/abs/2403.19971) [dataset](https://github.com/alibabadamo-academy/3D-Speaker)
- Enhancing Real-World Active Speaker Detection with Multi-Modal Extraction Pre-Training [arXiv 2024] [paper](https://arxiv.org/abs/2404.00861) [dataset1](https://github.com/clovaai/lookwhostalking) 
[dataset2](http://www.jaychakravarty.com/active-speaker-detection/) [dataset3](https://research.google.com/ava/download.html#ava_active_speaker_download)
#### 2023
- A Method of Audio-Visual Person Verification by Mining Connections between Time Series [ISCA] [paper](https://www.isca-archive.org/interspeech_2023/sun23_interspeech.html)
- AVoiD-DF: Audio-Visual Joint Learning for Detecting Deepfake [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/10081373)
- Getting More for Less: Using Weak Labels and AV-Mixup for Robust Audio-Visual Speaker Verification [arXiv 2023] [paper](https://arxiv.org/abs/2309.07115)
- On Understanding Context Modelling for Adaptive Authentication Systems [paper](https://dl.acm.org/doi/abs/10.1145/3582696)
- Self-Supervised Learning With Cluster-Aware-DINO for High-Performance Robust Speaker Verification [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/10314722)
- Modeling Long-Term Multimodal Representations for Active Speaker Detection With Spatio-Positional Encoder [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/10287283) [dataset](https://creativecommons.org/licenses/by/4.0/)

#### 2022
- AVA-AVD: Audio-visual Speaker Diarization in the Wild [ACM] [paper](https://dl.acm.org/doi/10.1145/3503161.3548027) [dataset and code](https://github.com/showlab/AVA-AVD)
- Learning Audio-Visual embedding for Person Verification in the Wild [arXiv 2022] [paper](http://arxiv.org/abs/2209.04093)
- Audio-Visual Cross-Attention Network for Robotic Speaker Tracking [IEEE] [paper](https://ieeexplore.ieee.org/document/9968308/)
- A Comprehensive Survey on Video SaliencyDetection With Auditory Information: TheAudio-Visual Consistency Perceptual is the Key! [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/9874810) [dataset](https://github.com/MengkeSong/SCDL)
#### 2020
- Audio-visual Speaker Recognition with a Cross-modal Discriminative Network [arXiv 2020] [paper](http://arxiv.org/abs/2008.03894)
### Attention mechanisms and feature enhancement
#### 2024
- Audio-Visual Person Verification based on Recursive Fusion of Joint Cross-Attention [arXiv 2024] [paper](http://arxiv.org/abs/2403.04654) [code](https://github.com/praveena2j/RJCAforSpeakerVerification)
- Audio-Visual Target Speaker Extraction with Reverse Selective Auditory Attention [arXiv 2024] [paper](https://arxiv.org/abs/2404.18501)
- 3D-Speaker-Toolkit: An Open Source Toolkit for Multi-Modal Speaker Verification and Diarization [arXiv 2024] [paper](https://arxiv.org/abs/2403.19971) [dataset](https://github.com/alibabadamo-academy/3D-Speaker)
- Multi-Input Multi-Output Target-Speaker Voice Activity Detection For Unified, Flexible, and Robust Audio-Visual Speaker Diarization [arXiv 2024] [paper](https://arxiv.org/abs/2401.08052) [dataset](https://github.com/facebookresearch/pytorchvideo)
#### 2023
- A Method of Audio-Visual Person Verification by Mining Connections between Time Series [ISCA] [paper](https://www.isca-archive.org/interspeech_2023/sun23_interspeech.html)
- AVoiD-DF: Audio-Visual Joint Learning for Detecting Deepfake [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/10081373)
- Single-branch Network for Multimodal Training [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/10097207)
- SELF-SUPERVISED AUDIO-VISUAL SPEAKER REPRESENTATION WITH CO-META LEARNING [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/10096925) [dataset](https:///www.robots.ox.ac.uk/vgg/research/CMBiometrics)

#### 2022
- Learning Audio-Visual embedding for Person Verification in the Wild [arXiv 2022] [paper](http://arxiv.org/abs/2209.04093)
- Audio-Visual Cross-Attention Network for Robotic Speaker Tracking [IEEE] [paper](https://ieeexplore.ieee.org/document/9968308/)

### Multimodal learning and knowledge distillation
#### 2024
- Self-supervised Reflective Learning through Self-distillation and Online Clustering for Speaker Representation Learning [arXiv 2024] [paper](https://arxiv.org/abs/2401.01473)
- LOOK, LISTEN AND RECOGNISE: CHARACTER-AWARE AUDIO-VISUAL SUBTITLING [arXiv 2024] [paper](https://ieeexplore.ieee.org/abstract/document/10446480)

#### 2022
- Deep Learning-Based Holistic Speaker Independent Visual Speech Recognition [IEEE] [paper](https://ieeexplore.ieee.org/document/9940584)
- USEV: Universal Speaker Extraction With Visual Cue [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/9887809)
#### 2021
- Audio-Visual Deep Neural Network for Robust Person Verification [IEEE/ACM] [paper](https://ieeexplore.ieee.org/document/9350195/)
- Knowledge Distillation from Multi-Modality to Single-Modality for Person Verification [ISCA] [paper](https://www.isca-archive.org/interspeech_2021/zhang21m_interspeech.html)
### Data Enhancement and Robustness
#### 2024
- Improving Speaker Verification With Noise-Aware Label Ensembling and Sample Selection: Learning and Correcting Noisy Speaker Labels [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/10542426) [dataset](http://www.festvox.org/cmu_arctic/)
#### 2023
- Cross-Modal Audio-Visual Co-Learning for Text-Independent Speaker Verification [arXiv] [paper](https://ieeexplore.ieee.org/abstract/document/10095883)
- Getting More for Less: Using Weak Labels and AV-Mixup for Robust Audio-Visual Speaker Verification [arXiv 2023] [paper](https://arxiv.org/abs/2309.07115)
- USEV: Universal Speaker Extraction With Visual Cue [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/9887809)
- Fast Search of Face Recognition Model for a Mobile Device Based on Neural Architecture Comparator [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/10168107) [dataset](https://creativecommons.org/licenses/by/4.0/)
#### 2021
- Audio-Visual Deep Neural Network for Robust Person Verification [IEEE/ACM] [paper](https://ieeexplore.ieee.org/document/9350195/)
#### 2020
- Audio-visual Speaker Recognition with a Cross-modal Discriminative Network [arXiv 2020] [paper](http://arxiv.org/abs/2008.03894)
### Deep Learning and Biometric Authentication
#### 2024
- Cross-Modal Learning Based Flexible Bimodal Biometric Authentication With Template Protection [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/10426779)
- Audio Super-Resolution With Robust Speech Representation Learning of Masked Autoencoder [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/10381805)
#### 2022
- Incorporating Visual Information in Audio Based Self-Supervised Speaker Recognition [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/9741340)
- Using Active Speaker Faces for Diarization in TV shows [arXiv 2022] [paper](https://arxiv.org/abs/2203.15961)
- Intel Labs at Ego4D Challenge 2022: A Better Baseline for Audio-Visual Diarization [arXiv 2022] [paper](https://arxiv.org/abs/2210.07764)
- LATE AUDIO-VISUAL FUSION FOR IN-THE-WILD SPEAKER DIARIZATION [arXiv 2022] [paper](https://arxiv.org/abs/2211.01299)  [dataset](https://github.com/serengil/deepface)
#### 2021
- Exploring Deep Learning for Joint Audio-Visual Lip Biometrics [arXiv 2021] [paper](http://arxiv.org/abs/2104.08510) [dataset](https://github.com/DanielMengLiu/DeepLip)
- Multimodal Emotion Recognition With Temporal and Semantic Consistency [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/9622137)
### Self-supervised learning
#### 2024
- Self-supervised Reflective Learning through Self-distillation and Online Clustering for Speaker Representation Learning [arXiv 2024] [paper](https://arxiv.org/abs/2401.01473)
- LOOK, LISTEN AND RECOGNISE: CHARACTER-AWARE AUDIO-VISUAL SUBTITLING [arXiv 2024] [paper](https://ieeexplore.ieee.org/abstract/document/10446480)
- Enhancing Real-World Active Speaker Detection with Multi-Modal Extraction Pre-Training [arXiv 2024] [paper](https://arxiv.org/abs/2404.00861) [dataset1](https://github.com/clovaai/lookwhostalking) 
[dataset2](http://www.jaychakravarty.com/active-speaker-detection/) [dataset3](https://research.google.com/ava/download.html#ava_active_speaker_download)
#### 2023
- Self-Supervised Training of Speaker Encoder With Multi-Modal Diverse Positive Pairs [IEEE] [paper](https://ieeexplore.ieee.org/abstract/document/10106039)
- On Understanding Context Modelling for Adaptive Authentication Systems [paper](https://dl.acm.org/doi/abs/10.1145/3582696)


## Dataset
### AVSpeech Dataset  [Download](https://github.com/naba89/AVSpeechDownloader)
- 结构： AVSpeech数据集是一个大规模的语音-视频数据集，包含超过5000小时的视频数据，每个视频都有相应的音频和字幕。
- 应用场景： 用于语音和视觉信号的联合分析，如语音识别、人物检测和跨模态个体验证。
### VoxCeleb Dataset  [Download](https://github.com/a-nagrani/VGGVox)
- 结构： VoxCeleb数据集包含数千小时的演讲者语音数据，以及他们在YouTube视频中的面部图像。
- 应用场景： 用于跨模态的说话人识别和认证，结合语音和面部图像进行说话人验证。
### AVDIAR Dataset  [Download](https://github.com/UTDTianGroup/AVDIAR2ASD)
- 结构： AVDIAR数据集是一个用于音频-视频说话人分离和识别的数据集，包含来自不同场景和环境的多模态数据。
- 应用场景： 用于音频和视频的说话人分离和识别，适用于语音会议记录、视频会议等场景。
### MIRACLE Dataset  [Download](https://github.com/coreysnipes/odm_data_miracle_park)
- 结构： MIRACLE数据集包含来自多个传感器（包括视觉、声音和生物特征）的数据，用于人的身份识别和认证。
- 应用场景： 用于综合多种生物特征进行个体身份识别和认证，例如在安全监控系统中结合多种传感器进行身份验证。
### CASIA Dataset  [Download](https://github.com/namtpham/casia2groundtruth)
- 结构： CASIA数据集包含大量的视觉数据，如面部图像和视频，用于人脸识别和认证。
- 应用场景： 虽然主要是用于单一模态的人脸识别，但可以与其他数据集结合，进行跨模态的身份识别研究，如结合语音或语言信息进行身份验证。
